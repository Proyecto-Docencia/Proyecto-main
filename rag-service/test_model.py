#!/usr/bin/env python3
"""
Script de prueba para verificar que el modelo gte-Qwen2-7B funciona correctamente.
"""
import os
os.environ["RAG_USE_GPU"] = "0"  # Forzar CPU para pruebas locales

def test_model_loading():
    """Prueba carga del modelo."""
    print("=" * 60)
    print("TEST 1: Carga del modelo")
    print("=" * 60)
    
    try:
        from sentence_transformers import SentenceTransformer
        print("âœ… sentence-transformers importado correctamente")
        
        model_name = "Alibaba-NLP/gte-Qwen2-7B-instruct"
        print(f"ğŸ“¦ Cargando modelo: {model_name}")
        
        model = SentenceTransformer(
            model_name,
            device="cpu",
            trust_remote_code=True
        )
        print(f"âœ… Modelo cargado: {model}")
        print(f"ğŸ“Š Dimensiones: {model.get_sentence_embedding_dimension()}")
        print(f"ğŸ“ Max sequence length: {model.max_seq_length}")
        
        return model
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_embeddings(model):
    """Prueba generaciÃ³n de embeddings."""
    print("\n" + "=" * 60)
    print("TEST 2: GeneraciÃ³n de embeddings")
    print("=" * 60)
    
    if model is None:
        print("âŒ Modelo no disponible")
        return
    
    try:
        test_texts = [
            "Â¿QuÃ© es la evaluaciÃ³n por competencias?",
            "Estrategias de enseÃ±anza efectivas"
        ]
        
        print(f"ğŸ”„ Generando embeddings para {len(test_texts)} textos...")
        embeddings = model.encode(
            test_texts,
            normalize_embeddings=True,
            show_progress_bar=True
        )
        
        print(f"âœ… Embeddings generados: {embeddings.shape}")
        print(f"ğŸ“Š Norma primer embedding: {(embeddings[0] ** 2).sum() ** 0.5:.4f}")
        
        # Calcular similitud
        similarity = (embeddings[0] @ embeddings[1].T)
        print(f"ğŸ”— Similitud entre textos: {similarity:.4f}")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()

def test_retrieval_module():
    """Prueba el mÃ³dulo retrieval."""
    print("\n" + "=" * 60)
    print("TEST 3: MÃ³dulo retrieval")
    print("=" * 60)
    
    try:
        import retrieval
        print("âœ… MÃ³dulo retrieval importado")
        
        print(f"ğŸ“¦ Modelo configurado: {retrieval.DEFAULT_MODEL}")
        print(f"ğŸ® GPU habilitada: {retrieval.USE_GPU}")
        print(f"ğŸ“ Cache path: {retrieval.EMBED_CACHE_PATH}")
        print(f"ğŸ”¢ TOP_K: {retrieval.TOP_K_DEFAULT}")
        print(f"ğŸ“Š MIN_SCORE: {retrieval.MIN_SCORE}")
        
        # Intentar cargar modelo
        print("\nğŸ”„ Cargando modelo a travÃ©s de retrieval...")
        model = retrieval._lazy_load_model()
        
        if model:
            print("âœ… Modelo cargado correctamente")
            
            # Probar embed_texts
            print("\nğŸ”„ Probando embed_texts...")
            test_texts = ["Texto de prueba"]
            embeddings = retrieval.embed_texts(test_texts)
            
            if embeddings is not None:
                print(f"âœ… Embeddings generados: {embeddings.shape}")
            else:
                print("âŒ Error generando embeddings")
        else:
            print("âŒ No se pudo cargar el modelo")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()

def test_ingest_module():
    """Prueba el mÃ³dulo ingest."""
    print("\n" + "=" * 60)
    print("TEST 4: MÃ³dulo ingest")
    print("=" * 60)
    
    try:
        import ingest
        print("âœ… MÃ³dulo ingest importado")
        
        # Probar chunking
        test_text = "Este es un pÃ¡rrafo de prueba.\n\nEste es otro pÃ¡rrafo.\n\nY este es un tercer pÃ¡rrafo muy largo que deberÃ­a ser dividido en mÃºltiples chunks porque excede la longitud mÃ¡xima permitida por el sistema de chunking, lo cual es importante para procesar documentos grandes de manera eficiente."
        
        chunks = ingest.chunk_text(test_text, max_len=100, overlap=20)
        print(f"âœ… Chunks generados: {len(chunks)}")
        for i, chunk in enumerate(chunks, 1):
            print(f"  Chunk {i}: {len(chunk)} caracteres")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸ§ª Iniciando pruebas del RAG Service\n")
    
    # Test 1: Cargar modelo directamente
    model = test_model_loading()
    
    # Test 2: Generar embeddings
    if model:
        test_embeddings(model)
    
    # Test 3: MÃ³dulo retrieval
    test_retrieval_module()
    
    # Test 4: MÃ³dulo ingest
    test_ingest_module()
    
    print("\n" + "=" * 60)
    print("âœ… Pruebas completadas")
    print("=" * 60)
